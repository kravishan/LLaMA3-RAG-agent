{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17211a8e-46b9-49cc-9719-49d56c9bd109",
   "metadata": {},
   "source": [
    "# LLaMA3 Local RAG agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25719747-5a9e-4d7a-8a73-e4a576ddbe8f",
   "metadata": {},
   "source": [
    "![Drawing](diagram.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f94d43-1e08-49a9-b34d-e065de0dd3ca",
   "metadata": {},
   "source": [
    "### Installing Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6dc36b-5a2f-4a51-8731-491c7804bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U langchain-nomic langchain_community tiktoken langchainhub langchain-openai chromadb langchain langgraph tavily-python nomic[local] langchain-text-splitters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6ca110-2224-470e-8d72-e5281a52956b",
   "metadata": {},
   "source": [
    "### Setting Up Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f757d146-8df0-4689-96af-a7d76d8b85af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = \"KEY\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1517c47d-ad7c-4678-a2bc-7c319b2d7a85",
   "metadata": {},
   "source": [
    "### Setting Up Local Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f9b20e3-3ab2-41f0-8b92-3951a0c58dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "local_llm = \"llama3\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f5fcb8-5f7f-4683-b3ea-04f03c2ff73f",
   "metadata": {},
   "source": [
    "### Set up and index documents for retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8514a847-3d9b-4665-bdc0-2fad102299a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Index\n",
    "\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "urls = [\n",
    "    \"https://www.oulu.fi/en/apply/international-programmes\",\n",
    "    \"https://www.oulu.fi/en/apply/how-apply/applying-bachelors-programmes\",\n",
    "    \"https://www.oulu.fi/en/apply/how-apply/applying-masters-programmes\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4889198e-42e6-4292-bcad-476d59378d67",
   "metadata": {},
   "source": [
    "### Set up a system to assess the relevance of retrieved documents to a user question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "ede2a4e1-412e-489f-870d-8c32e353285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your question:  How many master's programs are taught in English?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'score': 'yes'}\n"
     ]
    }
   ],
   "source": [
    "### Retrieval Grader\n",
    "\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     user\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n assistant\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Get user input for the question\n",
    "question = input(\"Please enter your question: \")\n",
    "\n",
    "# Retrieve documents based on the user question\n",
    "docs = retriever.invoke(question)\n",
    "doc_txt = docs[1].page_content\n",
    "\n",
    "# Assess the relevance of the retrieved document\n",
    "result = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feab6036-523e-4891-9c7f-f9d2b0ee692f",
   "metadata": {},
   "source": [
    "### Set up and perform a web search based on the user's question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5ad3b7b-9514-4284-b73e-9ca78d5c1790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Web search results: [{'url': 'https://www.studying-in-germany.org/master-degree/', 'content': \"Master's programs in Germany offer a diverse range of options, with many taught in English. They are known for their affordability, top-notch curricula, hands-on learning, and excellent career prospects. So, it's no wonder that master's degrees are the go-to choice for international students in Germany. During the 2021/2022 period, 42.6% of them (148,901 students) were [â€¦]\"}, {'url': 'https://beyondthestates.com/the-ultimate-guide-to-masters-degrees-in-europe/', 'content': \"Know this - there are over 8,231 accredited, 100% English-taught master's degrees to choose from across Europe; no foreign language required. More and more people from the US, and other countries, are heading to Europe for higher ed opportunities, and for good reason - there are so many affordable, high-quality English-taught programs ...\"}, {'url': 'https://www.gooverseas.com/blog/10-universities-where-you-can-study-abroad-in-english', 'content': 'ðŸ’° Average tuition cost: $5,000-$7,000 per semester ðŸŒŽ Percent of international students: 56% ðŸŽ“ Top majors: social sciences, environmental science, healthcare ðŸ“Œ QS university ranking: 256th. Most of the programs at Maastricht University are taught in English. In fact, it was one of the earlier international universities to adopt an English-dominant curriculum.'}, {'url': 'https://www.mygermanuniversity.com/articles/english-universities-in-germany', 'content': 'Yes! 220 universities in Germany offer English-taught programs for international students - More than 2,300 English Masters in Germany available. Germany has more than 400 universities which offer degree programs in all different types of subjects. As an international student, you may be wondering if any of these programs are taught in English.'}, {'url': 'https://beyondthestates.com/top-english-taught-universities-in-europe-for-masters/', 'content': \"The average cost for master's degree programs in the US ranges from $30,000 - $120,000 depending on whether a student is paying in-state tuition, out-of-state or private tuition. English-taught master's degree programs in Europe are much more affordable.\"}]\n"
     ]
    }
   ],
   "source": [
    "### Search\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "    \n",
    "# Initialize the web search tool\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "    \n",
    "# Perform a web search based on the user's question\n",
    "search_results = web_search_tool.invoke({\"query\": question})\n",
    "    \n",
    "# Print or use the search results\n",
    "print(\"Web search results:\", search_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8913fb-6bf4-43a4-8a96-e51387e242f0",
   "metadata": {},
   "source": [
    "### This cell sets up and executes a sequence to generate a specific search query based on the user's question and combined document content, then performs a web search using the generated query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "4212852a-f2ba-4086-bcd6-7abea057812d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search query: {'query': \"How many master's programs are taught in English at University of Oulu?\", 'type': 'search'}\n",
      "Web search results: [{'url': 'https://www.oulu.fi/en/apply/international-programmes', 'content': \"Applying to Bachelor's Programmes\\nApplying to Master's Programmes\\nLet us help you in finding your match\\nInternational Applicant's Guide 2024 - read it online\\nTake our study choice test and find your programme\\nPostal address\\n +358 294 48 0000\\nStreet address\\nPentti Kaiteran katu 1\\nLinnanmaa\\nFooter links\\nFooter links\\nChat with us\\nWe would like to talk to you via chat. UniOulu Ambassador Blog\\nAdmissions Contact\\nUniversity of Oulu in short\\nFounded in 1958, University of Oulu is one of the largest universities in Finland and one of the northernmost universities. University rankings\\nStudent Life\\nSustainable development in education\\nHow to apply\\nTo make your applicant journey smoother and to help you gather all the necessary documents on time, here are all important guidelines for you. 21\\nMaster's programmes\\n3\\nBachelor's programmes\\nTake a closer look at our selection to find your match.\\n\"}, {'url': 'https://www.findamasters.com/masters-degrees/institution/1454/university-of-oulu', 'content': 'List of English-taught Masters degrees from University of Oulu, may include scholarships, faqs, rankings & student life to help you select the right degree. Programmes ; ... More than 2,500 responsible, world-building professionals graduate from the University of Oulu every year. We are proud of our alumni body of 65,000 individuals having ...'}, {'url': 'https://www.mastersportal.com/universities/20alt=/university-of-oulu.html', 'content': \"Find every English-taught Master's degree from University of Oulu, ... University of Oulu's global impact is based on scientific breakthroughs and world-class innovations. 2.6 billion people use technology developed in Oulu. Oulu, the European Capital of Culture in 2026, is known for its highly educated people, easy-going atmosphere, tranquil ...\"}, {'url': 'https://www.oulu.fi/en/news/application-period-for-english-taught-degree-programmes-university-oulu-begins-january-3rd', 'content': \"The Finnish universities' first joint application will take place on January 3-17, 2024, when you can apply for English-taught degree programmes at the University of Oulu. University of Oulu offers a total of 848 study places in 21 Master's programmes and 3 Bachelor's programmes.\"}, {'url': 'https://www.oulu.fi/en/students/completing-studies/languages-and-communication/english', 'content': \"Contact teacher for Humanities' English teaching: Heather Kannasmaa. Faculty of Science. ... Students in International Master's Programs: ... FI-90014 University of Oulu university.of.oulu(at)oulu.fi Tel. +358 294 48 0000. Street address. Pentti Kaiteran katu 1 Linnanmaa.\"}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# Step 1: Initialize the Language Model\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Step 2: Define Prompt Template for Analysis\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are an internet search query generator. \\n\n",
    "    Here is the combined text of all documents: {combined_text}\n",
    "    Here is the user question: {question}\n",
    "    Your task is to understand and interpret the user's question to generate a specific search query for Google.\n",
    "\n",
    "    Question: {question} \n",
    "    Context: {combined_text} \n",
    "    \"\"\",\n",
    "    input_variables=[\"combined_text\", \"question\"],\n",
    ")\n",
    "\n",
    "# Step 3: Retrieve and Combine Document Content\n",
    "combined_text = \"\\n\".join([doc.page_content for doc in docs])\n",
    "\n",
    "# Step 4: Define Retrieval Analysis Pipeline\n",
    "retrieval_analysis = prompt | llm | JsonOutputParser()\n",
    "\n",
    "# Step 5: Invoke Retrieval Analysis with Combined Text and User Question\n",
    "analysis_result = retrieval_analysis.invoke({\"combined_text\": combined_text, \"question\": question})\n",
    "\n",
    "# Step 6: Print or Process the Analysis Result\n",
    "print(\"Search query:\", analysis_result)\n",
    "\n",
    "# Step 7: Perform Web Search Based on Generated Query\n",
    "query = analysis_result['query']\n",
    "\n",
    "# Initialize the web search tool\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "# Perform a web search based on the user's question\n",
    "search_results = web_search_tool.invoke({\"query\": query})\n",
    "\n",
    "# Step 8: Print or Use the Search Results\n",
    "print(\"Web search results:\", search_results)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "712a24f0-d61f-40d2-b4eb-920148d9a1b9",
   "metadata": {},
   "source": [
    "### Generate Answer from Retrieved Context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08af172d-a7b2-4dce-9510-19029952c558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Answer:\n",
      "According to the provided context, the University of Oulu offers 21 Master's programs that are taught in English.\n"
     ]
    }
   ],
   "source": [
    "### Generate\n",
    "\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "llm = ChatOllama(model=local_llm, temperature=0)\n",
    "\n",
    "\n",
    "# Post-processing\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "# Chain\n",
    "rag_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "# Generate answer\n",
    "generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "print(\"Generated Answer:\")\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2592eeac-a256-4107-8f12-0000fed4f420",
   "metadata": {},
   "source": [
    "### Evaluate whether a generated answer is grounded in a set of facts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "277ddb91-98cc-4a32-8ae7-3dd6b5d92f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Hallucination Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\" <|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. <|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = prompt | llm | JsonOutputParser()\n",
    "hallucination_grader.invoke({\"documents\": docs, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6b1ebf-6813-428a-93a3-c0df92978e08",
   "metadata": {},
   "source": [
    "### Assess whether a generated answer is useful for resolving a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "281ab2a9-4fdf-42ce-a301-65ce29c52a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'score': 'yes'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer Grader\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|> You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     <|eot_id|><|start_header_id|>user<|end_header_id|> Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} <|eot_id|><|start_header_id|>assistant<|end_header_id|>\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = prompt | llm | JsonOutputParser()\n",
    "answer_grader.invoke({\"question\": question, \"generation\": generation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe562f4b-1b72-412d-bbe1-98bd75b5a503",
   "metadata": {},
   "source": [
    "## Application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "9b88e65c-0636-4498-a098-582072c16242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your question:  How many programs are taught in the Finnish language?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The retrieved document is not relevant. Performing a web search...\n",
      "Web search results: [{'url': 'https://www.helsinki.fi/en/admissions-and-education/open-university/open-university-studies-degree-programme/languages-and-literatures-finland/finnish-foreigners', 'content': \"Open university: Finnish for foreigners. Open University studies from the Bachelor's Programme in the Languages and Literatures of Finland. You can study individual courses. At the Open University, you can study Beginner and Intermediate Level Courses (A1.1 - B2.1). Courses are taught in Finnish.\"}, {'url': 'https://www.helsinki.fi/en/admissions-and-education/international-students/studies-available-english', 'content': 'You can easily get by in Helsinki with English but learning the local language will give you more career options and can make your stay more rewarding. The University of Helsinki offers free Finnish language courses for enrolled exchange, visiting and international degree students. They are a fun way to learn the language, network with other ...'}, {'url': 'https://www.expat-finland.com/living_in_finland/language_training.html', 'content': 'Intensive summer course in Finnish language and culture Each July you can learn Finnish language and experience Finnish culture for almost 3 weeks in JyvÃ¤skylÃ¤! In Summer 2024 the course takes place July 1st to July 19th. The course includes an â‰ˆ75-hour teaching programme and â‰ˆ40-hour cultural programme. The course is open to anyone over ...'}, {'url': 'https://studies.helsinki.fi/instructions/article/finnish-international-students', 'content': \"The Finnish language courses organized by the Bachelor's Programme in the Languages and Literatures of Finland are intended for international degree, exchange and visiting students. Teaching is offered in three campuses: City centre, Viikki and Kumpula. Also online courses are offered every academic year. NEWS (18.5.2024)\"}, {'url': 'https://www.amscan.org/fellowships-and-grants/study-in-finland/', 'content': 'Using this great resource, the students can search for any program taught in a Finnish college. Summer courses are primarily intended for students of Finnish language or linguistics who have at least a working knowledge of Finnish language. There are four different levels to choose from and each course last for 3 to 4 weeks.'}]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "### Index Documents\n",
    "\n",
    "urls = [\n",
    "    \"https://www.oulu.fi/en/apply/international-programmes\",\n",
    "    \"https://www.oulu.fi/en/apply/how-apply/applying-bachelors-programmes\",\n",
    "    \"https://www.oulu.fi/en/apply/how-apply/applying-masters-programmes\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "### Retrieval Grader\n",
    "\n",
    "# LLM\n",
    "local_llm = \"llama3\"  \n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt Template for Relevance Grading\n",
    "relevance_prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     user\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n assistant\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = relevance_prompt | llm | JsonOutputParser()\n",
    "\n",
    "### Web Search Tool Initialization\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "### Generate Answer\n",
    "\n",
    "# Prompt Template for Answer Generation\n",
    "answer_prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise user\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: assistant\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "answer_llm = ChatOllama(model=local_llm, temperature=0)\n",
    "rag_chain = answer_prompt | answer_llm | StrOutputParser()\n",
    "\n",
    "# Format Documents Function\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "### Answer Grader\n",
    "\n",
    "# Prompt Template for Answer Grading\n",
    "answer_grading_prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     user Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} assistant\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = answer_grading_prompt | llm | JsonOutputParser()\n",
    "\n",
    "### Hallucination Grader\n",
    "\n",
    "# Prompt Template for Hallucination Grading\n",
    "hallucination_prompt = PromptTemplate(\n",
    "    template=\"\"\" system You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. user\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  assistant\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | llm | JsonOutputParser()\n",
    "\n",
    "### Main Workflow Function\n",
    "\n",
    "def main_workflow(question):\n",
    "    # Retrieve documents based on the user question\n",
    "    docs = retriever.invoke(question)\n",
    "    doc_txt = docs[0].page_content if docs else \"\"\n",
    "\n",
    "    # Assess the relevance of the retrieved document\n",
    "    result = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "\n",
    "    if result[\"score\"] == \"no\":\n",
    "        print(\"The retrieved document is not relevant. Performing a web search...\")\n",
    "        # Perform a web search based on the user's question\n",
    "        search_results = web_search_tool.invoke({\"query\": question})\n",
    "        print(\"Web search results:\", search_results)\n",
    "    elif result[\"score\"] == \"yes\":\n",
    "        print(\"The retrieved document is relevant. Generating an answer...\")\n",
    "        # Generate answer based on the documents\n",
    "        generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "        print(\"Generated Answer:\")\n",
    "        print(generation)\n",
    "\n",
    "        # Check the usefulness of the generated answer\n",
    "        answer_result = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        if answer_result[\"score\"] == \"yes\":\n",
    "            print(\"Answer Grader: Pass\")\n",
    "            \n",
    "            # Check for hallucinations\n",
    "            hallucination_result = hallucination_grader.invoke({\"documents\": format_docs(docs), \"generation\": generation})\n",
    "            if hallucination_result[\"score\"] == \"yes\":\n",
    "                print(\"Hallucination Grader: Pass\")\n",
    "            else:\n",
    "                print(\"Hallucination Grader: Fail\")\n",
    "        else:\n",
    "            print(\"Answer Grader: Fail\")\n",
    "\n",
    "### Run the Workflow\n",
    "\n",
    "# Get user input for the question\n",
    "question = input(\"Please enter your question: \")\n",
    "\n",
    "# Execute the main workflow\n",
    "main_workflow(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0deca305-03dc-43de-9639-ac7b8303b80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter your question:  How many master's programs are taught in English?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The retrieved document is relevant. Generating an answer...\n",
      "Generated Answer:\n",
      "According to the context, there are 21 master's programs taught in English at the University of Oulu.\n",
      "Answer Grader: Pass\n",
      "Hallucination Grader: Pass\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_nomic.embeddings import NomicEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "### Index Documents\n",
    "\n",
    "urls = [\n",
    "    \"https://www.oulu.fi/en/apply/international-programmes\",\n",
    "    \"https://www.oulu.fi/en/apply/how-apply/applying-bachelors-programmes\",\n",
    "    \"https://www.oulu.fi/en/apply/how-apply/applying-masters-programmes\",\n",
    "    \"https://www.oulu.fi/en/apply/how-apply/eligibility\",\n",
    "]\n",
    "\n",
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=250, chunk_overlap=0\n",
    ")\n",
    "doc_splits = text_splitter.split_documents(docs_list)\n",
    "\n",
    "# Add to vectorDB\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=doc_splits,\n",
    "    collection_name=\"rag-chroma\",\n",
    "    embedding=NomicEmbeddings(model=\"nomic-embed-text-v1.5\", inference_mode=\"local\"),\n",
    ")\n",
    "retriever = vectorstore.as_retriever()\n",
    "\n",
    "### Retrieval Grader\n",
    "\n",
    "# LLM\n",
    "local_llm = \"llama3\"  \n",
    "llm = ChatOllama(model=local_llm, format=\"json\", temperature=0)\n",
    "\n",
    "# Prompt Template for Relevance Grading\n",
    "relevance_prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are a grader assessing relevance \n",
    "    of a retrieved document to a user question. If the document contains keywords related to the user question, \n",
    "    grade it as relevant. It does not need to be a stringent test. The goal is to filter out erroneous retrievals. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question. \\n\n",
    "    Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     user\n",
    "    Here is the retrieved document: \\n\\n {document} \\n\\n\n",
    "    Here is the user question: {question} \\n assistant\n",
    "    \"\"\",\n",
    "    input_variables=[\"question\", \"document\"],\n",
    ")\n",
    "\n",
    "retrieval_grader = relevance_prompt | llm | JsonOutputParser()\n",
    "\n",
    "### Web Search Tool Initialization\n",
    "web_search_tool = TavilySearchResults(k=3)\n",
    "\n",
    "### Generate Answer\n",
    "\n",
    "# Prompt Template for Answer Generation\n",
    "answer_prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are an assistant for question-answering tasks. \n",
    "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. \n",
    "    Use three sentences maximum and keep the answer concise user\n",
    "    Question: {question} \n",
    "    Context: {context} \n",
    "    Answer: assistant\"\"\",\n",
    "    input_variables=[\"question\", \"context\"],\n",
    ")\n",
    "\n",
    "answer_llm = ChatOllama(model=local_llm, temperature=0)\n",
    "rag_chain = answer_prompt | answer_llm | StrOutputParser()\n",
    "\n",
    "# Format Documents Function\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "### Answer Grader\n",
    "\n",
    "# Prompt Template for Answer Grading\n",
    "answer_grading_prompt = PromptTemplate(\n",
    "    template=\"\"\"system You are a grader assessing whether an \n",
    "    answer is useful to resolve a question. Give a binary score 'yes' or 'no' to indicate whether the answer is \n",
    "    useful to resolve a question. Provide the binary score as a JSON with a single key 'score' and no preamble or explanation.\n",
    "     user Here is the answer:\n",
    "    \\n ------- \\n\n",
    "    {generation} \n",
    "    \\n ------- \\n\n",
    "    Here is the question: {question} assistant\"\"\",\n",
    "    input_variables=[\"generation\", \"question\"],\n",
    ")\n",
    "\n",
    "answer_grader = answer_grading_prompt | llm | JsonOutputParser()\n",
    "\n",
    "### Hallucination Grader\n",
    "\n",
    "# Prompt Template for Hallucination Grading\n",
    "hallucination_prompt = PromptTemplate(\n",
    "    template=\"\"\" system You are a grader assessing whether \n",
    "    an answer is grounded in / supported by a set of facts. Give a binary 'yes' or 'no' score to indicate \n",
    "    whether the answer is grounded in / supported by a set of facts. Provide the binary score as a JSON with a \n",
    "    single key 'score' and no preamble or explanation. user\n",
    "    Here are the facts:\n",
    "    \\n ------- \\n\n",
    "    {documents} \n",
    "    \\n ------- \\n\n",
    "    Here is the answer: {generation}  assistant\"\"\",\n",
    "    input_variables=[\"generation\", \"documents\"],\n",
    ")\n",
    "\n",
    "hallucination_grader = hallucination_prompt | llm | JsonOutputParser()\n",
    "\n",
    "### Main Workflow Function\n",
    "\n",
    "def main_workflow(question):\n",
    "    # Retrieve documents based on the user question\n",
    "    docs = retriever.invoke(question)\n",
    "    doc_txt = docs[0].page_content if docs else \"\"\n",
    "\n",
    "    # Assess the relevance of the retrieved document\n",
    "    result = retrieval_grader.invoke({\"question\": question, \"document\": doc_txt})\n",
    "\n",
    "    if result[\"score\"] == \"no\":\n",
    "        print(\"The retrieved document is not relevant. Performing a web search...\")\n",
    "        # Perform a web search based on the user's question\n",
    "        search_results = web_search_tool.invoke({\"query\": question})\n",
    "        print(\"Web search results:\", search_results)\n",
    "    elif result[\"score\"] == \"yes\":\n",
    "        print(\"The retrieved document is relevant. Generating an answer...\")\n",
    "        # Generate answer based on the documents\n",
    "        generation = rag_chain.invoke({\"context\": format_docs(docs), \"question\": question})\n",
    "        print(\"Generated Answer:\")\n",
    "        print(generation)\n",
    "\n",
    "        # Check the usefulness of the generated answer\n",
    "        answer_result = answer_grader.invoke({\"question\": question, \"generation\": generation})\n",
    "        if answer_result[\"score\"] == \"yes\":\n",
    "            print(\"Answer Grader: Pass\")\n",
    "            \n",
    "            # Check for hallucinations\n",
    "            hallucination_result = hallucination_grader.invoke({\"documents\": format_docs(docs), \"generation\": generation})\n",
    "            if hallucination_result[\"score\"] == \"yes\":\n",
    "                print(\"Hallucination Grader: Pass\")\n",
    "            else:\n",
    "                print(\"Hallucination Grader: Fail\")\n",
    "        else:\n",
    "            print(\"Answer Grader: Fail\")\n",
    "\n",
    "### Run the Workflow\n",
    "\n",
    "# Get user input for the question\n",
    "question = input(\"Please enter your question: \")\n",
    "\n",
    "# Execute the main workflow\n",
    "main_workflow(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027a7e15-fd55-434d-b066-7491dfd74c60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
